# WYA!? â€” Moderation tooling UI & operator experience

## Core philosophy

**Moderation is care work, not punishment.**

Tools should:

- Reduce burnout
- Increase clarity
- Prevent power abuse
- Support judgment, not replace it

**Moderators are not cops.**  
**They are gardeners.**

---

## Operator roles (not hierarchy)

Operators have capabilities, just like users.

### Examples:

- `can.review.reports`
- `can.issue.restrictions`
- `can.restore.capabilities`
- `can.resolve.appeals`
- `can.monitor.patterns`

**No one has god mode.**

---

## Operator UI principles

- Calm, low-contrast interface
- No alarmist colors
- No gamification
- No pressure metrics

**The UI should feel like a control room, not a battlefield.**

---

## Core moderation surfaces

### 1. Incident inbox

A prioritized, human-readable queue:

Each item shows:

- Severity (soft language)
- Context preview
- User age layer
- Prior history summary
- Time sensitivity

**No raw logs by default.**

### 2. Contextual replay view (critical)

Moderators never judge in isolation.

They see:

- Conversation before and after
- Tone indicators
- Participation balance
- Temporal flow
- Prior interactions between parties

**This prevents misinterpretation.**

### 3. User state panel

Shows:

- Active capabilities
- Recent restrictions
- Trust trajectory
- Appeal history
- Safety flags (explained)

**No hidden scores.**

---

## Action system (graduated, reversible)

Moderation actions are layered, not binary.

Actions include:

- Educational prompt
- Gentle warning
- Rate limiting
- Capability subtraction
- Temporary restriction
- Escalation for review

Every action:

- Has a reason
- Has a duration
- Has an appeal path

**Permanent bans require consensus.**

---

## Soft intervention UX

Moderators can send:

- System nudges
- Safety reminders
- Cooling-off prompts

Tone:

- Human
- Non-judgmental
- Specific

**No canned cop language.**

---

## Appeal handling

Appeals are:

- First-class citizens
- Routed to different operators
- Time-bound

Appeal UI shows:

- Original decision
- Reasoning
- User explanation
- Precedent suggestions

**This prevents ego-driven decisions.**

---

## Automation as assistant, not judge

AI assists by:

- Highlighting anomalies
- Summarizing patterns
- Suggesting actions

AI never:

- Issues bans
- Makes final decisions
- Hides context

**Humans remain accountable.**

---

## Burnout prevention

Operator UI enforces:

- Session time limits
- Mandatory breaks
- Rotating task types
- Emotional load balancing

**No infinite queues.**

**Healthy moderators make fair decisions.**

---

## Transparency tools

Operators can see:

- How often actions are reversed
- Bias indicators (aggregated, anonymized)
- Consistency metrics

**This keeps moderation honest.**

---

## Emergency tools (rare, controlled)

For critical threats only:

- Immediate isolation of accounts
- Rapid content suppression
- Safety broadcasts

These tools:

- Are logged
- Require justification
- Are reviewed post-incident

**No silent nukes.**

---

## Operator feedback loop

Moderators can:

- Flag unclear policies
- Suggest rule changes
- Annotate edge cases

**Policy evolves from reality, not theory.**

---

## The moderation social contract

Moderation in WYA!? feels like:

- Guidance, not punishment
- Care, not control
- Transparency, not secrecy
- Humanity, not bureaucracy

Users should feel:  
**"I was treated fairly, even if I disagreed."**

---

## Why these two documents matter

Together they ensure:

- Users trust the client with their voice
- Moderators trust the system with power
- Failures don't destroy confidence
- Authority never becomes arbitrary

**This is how WYA!? scales without becoming hostile.**

